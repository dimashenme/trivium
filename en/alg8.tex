\documentclass[12pt]{article}

\usepackage{theorem,amsmath,amssymb}

\input{listki.tex}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\listok{8}{ALGEBRA 8: Linear algebra: characteristic polynomial}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subs{Characteristic polynomial}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{opredelenie}
Consider a linear operator $A\in \End V$ over a vector space
$V$. Consider a vector $v\in V$ such that $A(v)= \lambda v$. 
This vector is called an {\bf eigenvector} and $\lambda$ is called an
{\bf eigenvalue} of the operator $A$. 
\end{opredelenie}

\begin{zadacha}
Consider a 2-dimensional vector space $V$ over $\R$,
endowed with non-degenerate bilinear symmetric form $g$, Ð°nd let
$A\in \End V$ be an orthogonal automorphism that is not equal to $\pm
Id$. Prove that if $g$ is positive definite or negative definite
(such forms are called {\bf definite forms})
then $A$ does not have eigenvectors. Prove that if $g$ is not definite
then $A$ has two linearly independent eigenvectors. What eigenvalues
can $A$ have in that case?
\end{zadacha}

\begin{zadacha}
Consider a set of fractions on the form $\frac{P(t)}{Q(t)}$ where
$P$, $Q$ are polynomials over $k$ and $Q\neq 0$. 
Consider an equivalence relation generated by the relation defined as
follows: 
$\frac{P(t)}{Q(t)}\sim\frac{P'(t)}{Q'(t)}$, if
\[ 
P(t) = Z(t) P'(t), \qquad\qquad Q(t) = Z(t) Q'(t)
\]
Define addition and multiplication on equivalence classes in the usual
manner:
\[ 
 \frac{P(t)}{Q(t)}+\frac{P'(t)}{Q'(t)}= 
\frac{P(t)Q'(t) + P'(t) Q(t)}{Q(t)Q'(t)}, \qquad\qquad
\frac{P(t)}{Q(t)}\frac{P'(t)}{Q'(t)} = \frac{P(t) P'(t))}{Q(t)Q'(t)}
\]
Prove that this structure is a field.
\end{zadacha}

\begin{opredelenie}
This field is called the {\bf field of rational functions of one
  variable} or just the  {\bf field of rational fractions}. It is
denoted $k(t)$.
\end{opredelenie}

\begin{zadacha}
Prove that this field is not an algebraic extension of $k$.
\end{zadacha}

\begin{zadacha}
Consider a $n$-dimensional vector space $V$ over $k$ and some other
field $K\supset k$. Consider the tensor product $K\otimes_k V$
endowed with the natural action of the multiplicative group $K^*$.
Prove that this is a vector space.  Prove that this vector space is
finite-dimensional over $K$ if $V$ is finite-dimensional over
$k$. Find the dimension of $K\otimes_k V$ over $K$ assuming the
dimension of $V$ over $k$ is known.
\end{zadacha}

Consider a vector space $V$ over $k$ and a linear operator $A\in \End
V$ on it.  Consider the tensor product of $V$ by the vector space
$k(t)$ over $k$, $V\otimes_k k(t)$.  The $A$ action can be naturally
extended to a linear operator on $V\otimes k(t)$. We will abuse the
notation and denote the corresponding operator 
$A\in \End_{k(t)} (V\otimes_k k(t))$ as $A$.

\begin{zadacha}[!]
Consider a linear operator $A\in \End V$ on a $n$-dimensional vector
space $V$ over $k$, and let $\det(t\cdot Id
  -A)\in k(t)$ be the determinant of the operator  $t\cdot Id -A$ that
  acts on $V\otimes_k k(t)$. Prove that this is a polynomial over $k$
  of degree $n$ with the leading coefficient 1.
\end{zadacha}
 
\begin{opredelenie}
This polynomial is called the {\bf characteristic polynomial of the
  operator $A$} and is denoted  $\chpoly_A(t)$.
\end{opredelenie}

\begin{zadacha}[!]
Let $\lambda$ be a root of the characteristic polynomial of $A$.
Prove that it is an eigenvalue of $A$. Prove that all $A$ eigenvalues
are the roots of $\chpoly_A(t)$.
\end{zadacha}

\begin{ukazanie} An operator  $\lambda Id - A$ has a non-trivial
  kernel iff  $\lambda$ is a root of $\chpoly_A(t)$.
\end{ukazanie}


\begin{zadacha}
Consider eigenvectors $v_1,\dots,v_n$ that correspond to distinct
eigenvalues. Prove that $v_1,\dots,v_n$ are linearly independent.
\end{zadacha}

\begin{zadacha}
Consider a linear operator $A\in \End V$ on a $n$-dimensional
vector space. Suppose that the characteristic polynomial has  $n$
distinct roots. Prove that $A$ is {\bf diagonalisable}, that is its
matrix is diagonal in some basis.
\end{zadacha}

\begin{zadacha}[*]
Consider a finite-dimensional vector space $V$ over $\C$.
Consider the set of all linear operators on $V$ as a vector space
with the natural topology on it. Prove that the set of diagonalisable operators
is dense in $\End V$. Prove that the set of non-diagonalisable
operators is nowhere dense.
\end{zadacha}


\begin{zadacha}[!]\label{_ch_poly_inva_Zadacha_}
Prove that $\chpoly_A(t) = \chpoly_{B A B^{-1}}(t)$
for any invertible linear operator $B$.
\end{zadacha}

\begin{opredelenie}
Consider a linear operator $A\in \End V$ on an $n$-dimensional 
vector space and his characteristic polynomial
$\chpoly_A(t) = t^n+ a_{n-1} t^{n-1} + a_{n-2} t^{n-2} + \dots$. The
coefficient $a_{n-1}$ is called the {\bf trace} of $A$ and is denoted
$\tr A$. 
\end{opredelenie}

\begin{zadacha}[!]
Consider an operator $A$ defined by a matrix $A^{i}_j$. Prove that 
$\tr A= \sum A^i_i$ (the sum of all numbers standing on the diagonal of
the matrix).
\end{zadacha}

\begin{zadacha}[*]
Prove that $\tr AB = \tr BA$ for any linear operators $A$, $B$.
\end{zadacha}

\begin{zamechanie}
If $B$ is invertible, this follows from~\ref{_ch_poly_inva_Zadacha_}.
\end{zamechanie}

\begin{zadacha}
Consider a finite-dimensional vector space $V$. Consider the homomorphism
$V\otimes V^* \arrow \Hom(V,V)$ that maps $v\otimes \lambda\in V\otimes V^*$
to $v'\arrow \lambda(v')\otimes v\in \Hom(V,V)$.
Prove that it is an isomorphism.
\end{zadacha}

\begin{zadacha}[*]
Consider $A\in \End V$ a linear operator on a finite-dimensional
vector space and $A\otimes A^*$, an operator induced by 
$A$ on $V \otimes V^*$. Consider the tensor
$\Id\in V \otimes V^*$ that corresponds to the identity operator under
the isomorphism $\Hom(V,V)\cong V\otimes V^*$ and the natural pairing
$V \otimes V^*\stackrel \mu \arrow k$.  
Prove that $\tr A = \mu(A\otimes A^*(\Id))$.
\end{zadacha}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subs{Upper triangular matrices}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{zadacha}
Let  $V' \subset V$ b $k$-dimensional subspace of a vector space and
$A\in \End V$ be an operator that preserves $V'$ (that is, $A$ maps 
$V'$ to itself). Choose a basis $e_1, \dots, e_n$ in $V$ such that
$e_1, \dots, e_k\in V'$. Prove that $A$ has the following form in this
basis:
\[
\begin{pmatrix}
*&*&* &\hdotsfor{1} &*&*&*\\
\vdots&\vdots&\vdots&
\ddots&\vdots&\vdots&\vdots\\
*&*&* &\hdotsfor{1} &*&*&*\\
0&0&0 &\hdotsfor{1} &*&*&*\\
\vdots&\vdots&\vdots&
\ddots &\vdots&\vdots&\vdots\\
0&0&0 &\hdotsfor{1} &*&*&*
\end{pmatrix}.
\]
(lower left rectangle $k\times (n-k)$ is filled with zeroes and other
coefficients are  arbitrary).
\end{zadacha}

\begin{opredelenie}
Consider an $n$-dimensional vector space $V$.
A sequence of subspaces
$0=V_0 \subset V_1 \subset V_2 \subset \dots \subset V_n = V$
is called a  {\bf flag} (or a  {\bf full flag}),
if $\dim V_i = i$. The basis $e_1, \dots, e_n$ is called 
{\bf adapted to the flab}, if $e_i \in V_i$.
We say that a linear operator  $A\in \End V$
{\bf preserves the flag $\{ V_i\}$}, if $A(V_i) \subset V_i$.
\end{opredelenie}

\begin{zadacha}[!]
  Let $A\in \End V$ be a linear operator. Prove that $A$ preserves
  some flag $\{ V_i\}$ iff $A$ can be represented by an
  upper-triangular matrix in in a basis $e_1, \dots,  e_n$ adapted to
  $\{ V_i \}$.
\end{zadacha}

\begin{zadacha}[!]
Let $V$ be a vector space over an algebraically closed field. Prove that
$A\in \End V$ preserves a flag
$0=V_0 \subset V_1 \subset V_2 \subset \dots \subset V_n = V$
(and consequently can be represented by an upper-triangular matrix in
some basis).
\end{zadacha}

\begin{ukazanie}
  Take as $V_1$ a vector subspace spanned by an eigenvector and apply
  induction.
\end{ukazanie}

\begin{zadacha}[*]
Consider an invertible linear operator  $A\in \End V$ on an
$n$-dimensional space that has  $n$ pairwise disjoint eigenvalues.
Consider a subalgebra $R_A$ in $\End V$ generated by $A$.
Prove that $\dim R_A=n$. 
\end{zadacha}

\begin{ukazanie}
Use the Vandermonde determinant.
\end{ukazanie}

\begin{zadacha}[*]
  Consider two commuting linear operators. Prove that the can be
  represented by two upper-triangular matrices in the same basis $e_1,
  \dots, e_n$.
\end{zadacha}

\begin{zadacha}[*]
  Consider $l$ pairwise commuting linear operators.  Prove that they
  all can be represented by upper-triangular matrices in the same
  basis $e_1, \dots, e_n$.
\end{zadacha}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subs{Symmetric and skew-symmetric matrices}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{opredelenie}
A matrix is called {\bf symmetric}
if it is equal to its transpose: $A = A^\bot$.
A matrix is called {\bf skew-symmetric}, or
{\bf antisymmetric}, if $A = - A^\bot$.
\end{opredelenie}

\begin{opredelenie}
Consider a vector space $V$ together with a non-degenerate bilinear
symmetric form $g$ and a linear operator $A\in \End V$. The operator
$A$ is called {\bf symmetric} if for any  $x, y\in V$ we have
$g(Ax, y) = g(x, Ay)$; it is called {\bf skew-symmetric},
if we have $g(Ax, y) = -g(x, Ay)$.
\end{opredelenie}

\begin{opredelenie}
Let $V$ be a vector space endowed with a non-degenerate bilinear
symmetric form $g$. Recall that a basis $e_1, \dots, e_n\in V$ is
called {\bf orthonormal} if  $e_i$-s are pairwise orthogonal and
$g(e_i,e_i)=1$. 
\end{opredelenie}

\begin{zadacha}
Let $V$ be a vector space endowed with a non-degenerate bilinear
symmetric form  $g$ and $e_1, \dots, e_n$ be an orthonormal
basis. Consider a linear operator $A\in \End V$. Prove that $A$ is
symmetric iff its matrix is symmetric, and antisymmetric iff its
matrix is antisymmetric.
\end{zadacha}

\begin{zadacha}\label{_izo_biline_Zadacha_}
Let $V$ be a finite-dimensional vector space endowed with a bilinear
non-degenerate form $g$. Prove that any bilinear form can be a
represented as $g(Ax, y)$ for some linear operator $A$ and that such
an operator is unique.
\end{zadacha}

\begin{zamechanie}
In the previous problem setting assume that
$g$ is symmetric. Obviously, The form $g(Ax, y)$ is symmetric iff  
$A$ is symmetric, and antisymmetric iff $A$ is antisymmetric.
\end{zamechanie}

\begin{zadacha}
Let $V$ be a finite-dimensional vector space. The space of bilinear
forms is naturally isomorphic to  $V^*\otimes V^*$ and the space $\End
V$ is naturally isomorphic to $V\otimes V^*$. A form $g$ induces an
isomorphism between  $V$ and $V^*$. This gives an isomorphism between
$V^*\otimes V^*$ and $V\otimes V^*$, i.e. between the bilinear forms
and the linear operators. Prove that this isomorphism coincides with
the one constructed in the Problem~\ref{_izo_biline_Zadacha_}.
\end{zadacha}

\begin{zadacha}[!]\label{_sokhra_podpro_Zadacha_}
Let $V$ be a finite-dimensional vector space endowed with
non-degenerate bilinear symmetric form $g$ and let $A$ by  a symmetric
operator. Suppose $A$ preserve the subspace  $V'\subset V$. Prove that
$A$ preserves the orthogonal complement to  $V'$.
\end{zadacha}

\begin{opredelenie}
  Let $V$ be a vector space over $\R$ and $V \otimes \C$ it the tensor
  product of the latter with $\C$. Since $\C \cong \R \oplus \1\R$,
  there is an isomorphism $V\otimes \C\cong V\oplus \1 V$. That means
  that one can consider a \textbf{real} ($\Re v$) and \textbf{imaginary}
  part ($\Im v$) of any vector $v\in V\otimes \C$.
\end{opredelenie}

\begin{zadacha}\label{_okompleksi_Zadacha_}
  Let $V$ be a vector space over $\R$ endowed with a bilinear
  symmetric form $g$. Consider a complex vector space $V\otimes \C$
  and continue $g$ to $V\otimes \C$ using the linearity of the
  bilinear complex-valued form.  For any vector $v\in V\otimes \C$
  denote by $\bar v$ the vector $\Re(v) - \1 \Im(v)$ (this vector is
  called the {\bf complex conjugate to $v$}). Prove that $g(v, \bar v)
  = g(\Re(v), \Re(v))+g(\Im(v), \Im(v))$.
\end{zadacha}


\begin{zadacha}[!]\label{_veshche_korni_Zadacha_}
Let  $V$ by a finite-dimensional vector space over $\R$ of dimension
$n$ endowed with a positive definite bilinear symmetric form $g$ (such
space is called {\bf Euclidean}), and let 
$A$  be a symmetric operator and  $P(t)$ be his characteristic
polynomial. Prove that $P(t)$ has exactly $n$ real roots.
\end{zadacha}

\begin{ukazanie}
  Consider the action of $A$ on $V\otimes \C$, and let $v$ be the
  eigenvector corresponding to a non-real eigenvalue. Prove that $g(v,
  \bar v)=0$. Use the Problem~\ref{_okompleksi_Zadacha_}.
\end{ukazanie}

\begin{zadacha}[!]
Let $V$ be a Euclidean space and $A\in V$ be a symmetric operator.
Prove that $V$ has an orthogonal basis of eigenvectors of $A$. In
other words, $A$ is diagonalisable in an orthonormal basis.
\end{zadacha}

\begin{ukazanie}
Use the Problems~\ref{_veshche_korni_Zadacha_}
and \ref{_sokhra_podpro_Zadacha_}.
\end{ukazanie}

\begin{zadacha}[*]
Let $V$ be a finite-dimensional vector space over $\R$ endowed with a
non-degenerate but non necessary positive definite bilinear symmetric
form. Is any symmetric operator diagonalisable?
\end{zadacha}

\begin{zadacha}[*]
Let $V$ be a Euclidean space and
$A\in V$ be a skew-symmetric operator. Denote by $\omega$ the
skew-symmetric form $g(A\cdot, \cdot)$. Let
$v$ be an eigenvector of the operator $A^2$
(with a non-zero eigenvalue).  Prove that  $\omega$ is non-degenerate
on the linear span  
$\langle v, A(v)\rangle$.
\end{zadacha}

\begin{zadacha}[*]
In the previous problem setting prove that in some orthonormal basis
$e_1, \dots, e_{2m}, e_{2m+1}, \dots, e_n$
$\omega$ is of the form
\[ \sum_{i=0}^{m-1} \alpha_i e^{i+1}\wedge e^{i+2}.\]
\end{zadacha}

\begin{zadacha}[*]
  Let $A$ be a skew-symmetric operator defined on a Euclidean space
  and $\det A$ be its determinant. Consider $\det A$ as a polynomial
  of matrix coefficients of $A$ in some basis. Prove that in a
  odd-dimensional space $V$ this determinant polynomial is identically
  zero. Prove that $\det A$ is a full square of some other polynomial
  of matrix coefficients. This polynomial is called the {\bf Pfaffian
    of $A$}.
\end{zadacha}

\begin{ukazanie}
Let $2m= \dim V$.
Consider the bilinear form $\omega$ represented in the form
above. Prove that  $\omega^{m}$ (considered as an element of the
Grassmann algebra $\Lambda^*(V^*)$) is proportional to  $e^1\wedge e^2\wedge \dots \wedge e^{2m}$
with a polynomial coefficient  $Q$, moreover $Q^2 = \det A$.
\end{ukazanie}

\end{document}
